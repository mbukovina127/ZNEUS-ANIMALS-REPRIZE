{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Machine Learning - Image Classification",
   "id": "de369611418338b5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T10:30:35.185511Z",
     "start_time": "2025-11-28T10:30:30.645411Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#importing\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch import optim\n",
    "\n",
    "from utils import *"
   ],
   "id": "3d39034e8143cb63",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Database importing",
   "id": "36370301af86524b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T10:31:01.019659Z",
     "start_time": "2025-11-28T10:30:35.193536Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# TODO: pouzi toto martin\n",
    "load_dotenv()\n",
    "DAT_PATH = os.getenv(\"TRAIN_DATASET_PATH\")\n",
    "\n",
    "ANIMALS_DATAFRAME = load_dataset_info(\"../data/archive/raw-img\")\n",
    "ANIMALS_DATAFRAME.head()"
   ],
   "id": "d9710a1ff3f0f4bf",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                            filepath label format color_mode  \\\n",
       "0  ..\\data\\archive\\raw-img\\cane\\OIF-e2bexWrojgtQn...  cane  .jpeg        RGB   \n",
       "1  ..\\data\\archive\\raw-img\\cane\\OIP---A27bIBcUgX1...  cane  .jpeg        RGB   \n",
       "2  ..\\data\\archive\\raw-img\\cane\\OIP---cByAiEbIxIA...  cane  .jpeg        RGB   \n",
       "3  ..\\data\\archive\\raw-img\\cane\\OIP---ZIdwfUcJeVx...  cane  .jpeg        RGB   \n",
       "4  ..\\data\\archive\\raw-img\\cane\\OIP---ZRsOF7zsMqh...  cane  .jpeg        RGB   \n",
       "\n",
       "   bit_depth  width  height   area  aspect_ratio  brightness  \n",
       "0          8    300     225  67500      1.333333  162.620696  \n",
       "1          8    300     214  64200      1.401869  171.896558  \n",
       "2          8    153     300  45900      0.510000  121.562360  \n",
       "3          8    300     225  67500      1.333333  121.487343  \n",
       "4          8    300     225  67500      1.333333  113.152356  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filepath</th>\n",
       "      <th>label</th>\n",
       "      <th>format</th>\n",
       "      <th>color_mode</th>\n",
       "      <th>bit_depth</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>area</th>\n",
       "      <th>aspect_ratio</th>\n",
       "      <th>brightness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>..\\data\\archive\\raw-img\\cane\\OIF-e2bexWrojgtQn...</td>\n",
       "      <td>cane</td>\n",
       "      <td>.jpeg</td>\n",
       "      <td>RGB</td>\n",
       "      <td>8</td>\n",
       "      <td>300</td>\n",
       "      <td>225</td>\n",
       "      <td>67500</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>162.620696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>..\\data\\archive\\raw-img\\cane\\OIP---A27bIBcUgX1...</td>\n",
       "      <td>cane</td>\n",
       "      <td>.jpeg</td>\n",
       "      <td>RGB</td>\n",
       "      <td>8</td>\n",
       "      <td>300</td>\n",
       "      <td>214</td>\n",
       "      <td>64200</td>\n",
       "      <td>1.401869</td>\n",
       "      <td>171.896558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>..\\data\\archive\\raw-img\\cane\\OIP---cByAiEbIxIA...</td>\n",
       "      <td>cane</td>\n",
       "      <td>.jpeg</td>\n",
       "      <td>RGB</td>\n",
       "      <td>8</td>\n",
       "      <td>153</td>\n",
       "      <td>300</td>\n",
       "      <td>45900</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>121.562360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>..\\data\\archive\\raw-img\\cane\\OIP---ZIdwfUcJeVx...</td>\n",
       "      <td>cane</td>\n",
       "      <td>.jpeg</td>\n",
       "      <td>RGB</td>\n",
       "      <td>8</td>\n",
       "      <td>300</td>\n",
       "      <td>225</td>\n",
       "      <td>67500</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>121.487343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>..\\data\\archive\\raw-img\\cane\\OIP---ZRsOF7zsMqh...</td>\n",
       "      <td>cane</td>\n",
       "      <td>.jpeg</td>\n",
       "      <td>RGB</td>\n",
       "      <td>8</td>\n",
       "      <td>300</td>\n",
       "      <td>225</td>\n",
       "      <td>67500</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>113.152356</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T10:31:01.140016Z",
     "start_time": "2025-11-28T10:31:01.130385Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_df, test_df = train_test_split(ANIMALS_DATAFRAME, test_size=0.05, random_state=42)\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.0526, random_state=42)"
   ],
   "id": "5cc1f9d00df31223",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T10:31:01.184802Z",
     "start_time": "2025-11-28T10:31:01.175959Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#setting up dataloaders\n",
    "\n",
    "TARGET_SIZE = (256, 256)\n",
    "MAX_SIZE = 500\n",
    "BATCH_SIZE = 42\n",
    "NUM_CLASSES = ANIMALS_DATAFRAME.label.nunique()\n",
    "CLASS_LABELS = {name: idx for idx, name in enumerate(np.sort(ANIMALS_DATAFRAME.label.unique()))}\n",
    "\n",
    "# vypocet frekvencie augmentacie -> aby nebol model biasnuty iba na majoritne categorie obrazkov\n",
    "counts = train_df.label.value_counts()\n",
    "max_count = counts.max()\n",
    "aug_strength = (max_count / counts).to_dict()\n",
    "\n",
    "print(aug_strength)\n",
    "\n",
    "train_gen = AnimalImageGenerator(\n",
    "    df=train_df,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    target_size=TARGET_SIZE,\n",
    "    num_classes=NUM_CLASSES,\n",
    "    augment=True,\n",
    "    shuffle=True,\n",
    "    aug_strength=aug_strength,\n",
    "    max_size=MAX_SIZE,\n",
    "    class_mapping=CLASS_LABELS,\n",
    ")\n",
    "\n",
    "test_gen = AnimalImageGenerator(\n",
    "    df=test_df,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    target_size=TARGET_SIZE,\n",
    "    num_classes=NUM_CLASSES,\n",
    "    augment=False,\n",
    "    shuffle=False,\n",
    "    max_size=MAX_SIZE,\n",
    "    class_mapping=CLASS_LABELS,\n",
    ")\n",
    "\n",
    "val_gen = AnimalImageGenerator(\n",
    "    df=val_df,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    target_size=TARGET_SIZE,\n",
    "    num_classes=NUM_CLASSES,\n",
    "    augment=False,\n",
    "    shuffle=False,\n",
    "    max_size=MAX_SIZE,\n",
    "    class_mapping=CLASS_LABELS,\n",
    ")\n"
   ],
   "id": "6a18fe6f83c8e0b6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cane': 1.0, 'ragno': 1.013622719926114, 'gallina': 1.5667380442541041, 'cavallo': 1.8688803746275011, 'farfalla': 2.32521186440678, 'mucca': 2.564252336448598, 'scoiattolo': 2.642986152919928, 'pecora': 2.670316301703163, 'gatto': 2.9344919786096257, 'elefante': 3.408385093167702}\n",
      "---\n",
      "Total images: 23561\n",
      "Num classes: 10\n",
      "---\n",
      "---\n",
      "Total images: 1309\n",
      "Num classes: 10\n",
      "---\n",
      "---\n",
      "Total images: 1309\n",
      "Num classes: 10\n",
      "---\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T10:31:01.431487Z",
     "start_time": "2025-11-28T10:31:01.221393Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#testovaci vypis\n",
    "images, labels = train_gen[0]     # zavol√° __getitem__(0) pre prvy batch\n",
    "print(\"Images shape:\", images.shape)\n",
    "print(\"Labels shape:\", labels.shape)\n",
    "print(\"Image dtype:\", images.dtype)\n",
    "print(\"Label sample:\", labels[0])"
   ],
   "id": "d2b55cb221211796",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images shape: (56, 256, 256, 3)\n",
      "Labels shape: (56,)\n",
      "Image dtype: uint8\n",
      "Label sample: 0\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Model implemetation",
   "id": "fbbb57b435bc15a3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T10:31:01.447846Z",
     "start_time": "2025-11-28T10:31:01.445591Z"
    }
   },
   "cell_type": "code",
   "source": "import torch.nn.functional as fun",
   "id": "f2c724cb5afb2a3d",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T10:31:01.456141Z",
     "start_time": "2025-11-28T10:31:01.451996Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#PRE TUTO FUNKCIU NEGENERUJ ZIADNE KOMENTARE\n",
    "class ImageClassifier(nn.Module):\n",
    "    def __init__(self, classes: int):\n",
    "        super(ImageClassifier, self).__init__()\n",
    "        self.numberOfClasses = classes\n",
    "\n",
    "        # Convolution layres ONLY WORKS with RGB because of in_channels, kernel_size for filtering is 3 stride 1 padding 1 for size preservation\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1,padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "\n",
    "        # Significant for grad-CAM\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1,padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "\n",
    "        #\n",
    "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1,padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "\n",
    "        # Adaptive pooling to make model input-size agnostic / dont want to use it for now\n",
    "        # self.adaptive_pool = nn.AdaptiveAvgPool2d((4, 4))\n",
    "\n",
    "        #size is determined by conv channels and the reduction in size by conv channels\n",
    "        #channels * width * height because 256 /2 /2 /2 is 32\n",
    "        self.fc1 = nn.Linear(in_features=64*32*32, out_features=128)\n",
    "        self.fc2 = nn.Linear(in_features=128, out_features=self.numberOfClasses)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #Block 1\n",
    "        x = fun.relu(self.bn1(self.conv1(x)))\n",
    "        x = fun.max_pool2d(x, kernel_size=2) # zmensovanie velkosti\n",
    "\n",
    "        x = fun.relu(self.bn2(self.conv2(x)))\n",
    "        x = fun.max_pool2d(x, kernel_size=2)\n",
    "\n",
    "        x = fun.relu(self.bn3(self.conv3(x)))\n",
    "        x = fun.max_pool2d(x, kernel_size=2)\n",
    "\n",
    "        x = x.reshape(x.size(0), -1)\n",
    "\n",
    "        x = fun.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ],
   "id": "4917211e7761bf70",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Grad CAM Implementation\n",
    " -- On hold\n",
    " https://medium.com/@codetrade/grad-cam-in-pytorch-a-powerful-tool-for-visualize-explanations-from-deep-networks-bdc7caf0b282\n",
    "\n"
   ],
   "id": "78dd9163027c853"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Model Training",
   "id": "8a49ee32f84410ae"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Training function",
   "id": "b9e0ce08452c2799"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T10:31:01.465315Z",
     "start_time": "2025-11-28T10:31:01.460154Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_model(model: nn.Module,\n",
    "                train_loader: AnimalImageGenerator,\n",
    "                val_loader: AnimalImageGenerator,\n",
    "                criterion: nn.Module,\n",
    "                optimizer: torch.optim.Optimizer,\n",
    "                device: torch.device,\n",
    "                epochs: int = 10,\n",
    "                scheduler=None):\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    for epoch in range(1, epochs+1):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in train_loader:\n",
    "            images = torch.from_numpy(images).permute(0,3,1,2).float().to(device) # permute because the convolution layer gets input in the wrong order\n",
    "            # images = torch.tensor(images, dtype=torch.float32, device=device)\n",
    "            labels = torch.tensor(labels, dtype=torch.long, device=device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "        train_loss = running_loss / total\n",
    "        train_acc = correct / total\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images = torch.tensor(images, dtype=torch.float32, device=device)\n",
    "                labels = torch.tensor(labels, dtype=torch.long, device=device)\n",
    "\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                val_loss += loss.item() * images.size(0)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                val_correct += (preds == labels).sum().item()\n",
    "                val_total += labels.size(0)\n",
    "\n",
    "        val_loss /= val_total\n",
    "        val_acc = val_correct / val_total\n",
    "\n",
    "        if scheduler:\n",
    "            scheduler.step(val_loss)\n",
    "\n",
    "        print(f\"Epoch {epoch}/{epochs} | \"\n",
    "              f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f} | \"\n",
    "              f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "        ## TODO: add f1 score"
   ],
   "id": "ccfadbd579e53f46",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Training",
   "id": "5bf862f9c3a11a52"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-11-28T10:31:01.470570Z"
    }
   },
   "cell_type": "code",
   "source": [
    "img_class_model = ImageClassifier(NUM_CLASSES)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(img_class_model.parameters(), lr=0.001, momentum=0.9)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "train_model(model=img_class_model,\n",
    "            train_loader=train_gen,\n",
    "            val_loader=val_gen,\n",
    "            criterion=criterion,\n",
    "            optimizer=optimizer,\n",
    "            device=device,\n",
    "            epochs=10,\n",
    "            scheduler=None)\n"
   ],
   "id": "6bba75ad8d81bff2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Hyper parameter sweeping",
   "id": "6896e65a374b6d44"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "9d7c4537a330f912"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
