{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Machine Learning - Image Classification",
   "id": "de369611418338b5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-29T11:41:44.453827Z",
     "start_time": "2025-11-29T11:41:44.451272Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#importing\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as fun\n",
    "from torch import Tensor\n",
    "\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch import optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "from utils import *"
   ],
   "id": "3d39034e8143cb63",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Database importing",
   "id": "36370301af86524b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-29T10:58:28.821813Z",
     "start_time": "2025-11-29T10:58:14.707644Z"
    }
   },
   "cell_type": "code",
   "source": [
    "load_dotenv()\n",
    "DAT_PATH = os.getenv(\"TRAIN_DATASET_PATH\")\n",
    "\n",
    "ANIMALS_DATAFRAME = load_dataset_info(\"../data/archive/raw-img\")"
   ],
   "id": "d9710a1ff3f0f4bf",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-29T10:58:28.880193Z",
     "start_time": "2025-11-29T10:58:28.870176Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_df, test_df = train_test_split(ANIMALS_DATAFRAME, test_size=0.05, random_state=37)\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.0526, random_state=37)"
   ],
   "id": "5cc1f9d00df31223",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-29T10:58:28.893600Z",
     "start_time": "2025-11-29T10:58:28.885629Z"
    }
   },
   "cell_type": "code",
   "source": [
    "TARGET_SIZE = (256, 256)\n",
    "MAX_SIZE = 500\n",
    "BATCH_SIZE = 64\n",
    "NUM_CLASSES = ANIMALS_DATAFRAME.label.nunique()\n",
    "CLASS_LABELS = {name: idx for idx, name in enumerate(np.sort(ANIMALS_DATAFRAME.label.unique()))}\n",
    "\n",
    "# vypocet frekvencie augmentacie -> aby nebol model biasnuty iba na majoritne categorie obrazkov\n",
    "counts = train_df.label.value_counts()\n",
    "max_count = counts.max()\n",
    "aug_strength = (max_count / counts).to_dict()\n",
    "\n",
    "print(aug_strength)\n"
   ],
   "id": "abb2166b0f0fe21b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cane': 1.0, 'ragno': 1.0809676623056035, 'gallina': 1.5667262969588551, 'cavallo': 1.8399159663865545, 'mucca': 2.606547619047619, 'scoiattolo': 2.615890083632019, 'farfalla': 2.9748641304347827, 'pecora': 3.3684615384615384, 'gatto': 4.047134935304991, 'elefante': 4.4912820512820515}\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-29T10:58:28.899964Z",
     "start_time": "2025-11-29T10:58:28.897463Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#setting up dataloaders#\n",
    "#   POMALE\n",
    "#\n",
    "# train_gen = AnimalImageGenerator(\n",
    "#     df=train_df,\n",
    "#     batch_size=BATCH_SIZE,\n",
    "#     target_size=TARGET_SIZE,\n",
    "#     num_classes=NUM_CLASSES,\n",
    "#     augment=True,\n",
    "#     shuffle=True,\n",
    "#     aug_strength=aug_strength,\n",
    "#     max_size=MAX_SIZE,\n",
    "#     class_mapping=CLASS_LABELS,\n",
    "# )\n",
    "#\n",
    "# test_gen = AnimalImageGenerator(\n",
    "#     df=test_df,\n",
    "#     batch_size=BATCH_SIZE,\n",
    "#     target_size=TARGET_SIZE,\n",
    "#     num_classes=NUM_CLASSES,\n",
    "#     augment=False,\n",
    "#     shuffle=False,\n",
    "#     max_size=MAX_SIZE,\n",
    "#     class_mapping=CLASS_LABELS,\n",
    "# )\n",
    "#\n",
    "# val_gen = AnimalImageGenerator(\n",
    "#     df=val_df,\n",
    "#     batch_size=BATCH_SIZE,\n",
    "#     target_size=TARGET_SIZE,\n",
    "#     num_classes=NUM_CLASSES,\n",
    "#     augment=False,\n",
    "#     shuffle=False,\n",
    "#     max_size=MAX_SIZE,\n",
    "#     class_mapping=CLASS_LABELS,\n",
    "# )\n"
   ],
   "id": "6a18fe6f83c8e0b6",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-29T10:58:28.915171Z",
     "start_time": "2025-11-29T10:58:28.908922Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.utils.data import WeightedRandomSampler\n",
    "\n",
    "\n",
    "#CHATOVINA ale ze vraj rychla\n",
    "\n",
    "def create_sampler(df, class_mapping):\n",
    "    labels = df[\"label\"].map(class_mapping).values\n",
    "    class_counts = np.bincount(labels)\n",
    "    class_weights = 1.0 / class_counts\n",
    "\n",
    "    sample_weights = class_weights[labels]\n",
    "    sampler = WeightedRandomSampler(\n",
    "        torch.from_numpy(sample_weights).float(),\n",
    "        num_samples=len(sample_weights),\n",
    "        replacement=True\n",
    "    )\n",
    "    return sampler\n",
    "\n",
    "train_dataset = AnimalDataset(\n",
    "    df=train_df,\n",
    "    class_mapping=CLASS_LABELS,\n",
    "    augment=True,\n",
    "    target_size=TARGET_SIZE,\n",
    ")\n",
    "\n",
    "val_dataset = AnimalDataset(\n",
    "    df=val_df,\n",
    "    class_mapping=CLASS_LABELS,\n",
    "    augment=False,\n",
    "    target_size=TARGET_SIZE,\n",
    ")\n",
    "\n",
    "sampler = create_sampler(train_df, CLASS_LABELS)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    sampler=sampler,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=True\n",
    ")\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=True\n",
    ")\n"
   ],
   "id": "22dcbd10e815ce22",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Model implemetation",
   "id": "fbbb57b435bc15a3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-29T10:58:28.922784Z",
     "start_time": "2025-11-29T10:58:28.919216Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#PRE TUTO FUNKCIU NEGENERUJ ZIADNE KOMENTARE\n",
    "class ImageClassifier(nn.Module):\n",
    "    def __init__(self, classes: int):\n",
    "        super(ImageClassifier, self).__init__()\n",
    "        self.numberOfClasses = classes\n",
    "\n",
    "        # Convolution layres ONLY WORKS with RGB because of in_channels, kernel_size for filtering is 3 stride 1 padding 1 for size preservation\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1,padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "\n",
    "        # Significant for grad-CAM\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1,padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1,padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "\n",
    "        # Adaptive pooling to make model input-size agnostic / dont want to use it for now\n",
    "        # self.adaptive_pool = nn.AdaptiveAvgPool2d((4, 4))\n",
    "\n",
    "        #size is determined by conv channels and the reduction in size by conv channels\n",
    "        #channels * width * height because 256 /2 /2 /2 is 8\n",
    "        self.fc1 = nn.Linear(in_features=64*32*32, out_features=128)\n",
    "        self.fc2 = nn.Linear(in_features=128, out_features=self.numberOfClasses)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #Block 1\n",
    "        x = fun.leaky_relu(self.bn1(self.conv1(x)))\n",
    "        x = fun.max_pool2d(x, kernel_size=2) # zmensovanie velkosti\n",
    "\n",
    "        x = fun.leaky_relu(self.bn2(self.conv2(x)))\n",
    "        x = fun.max_pool2d(x, kernel_size=2)\n",
    "\n",
    "        x = fun.leaky_relu(self.bn3(self.conv3(x)))\n",
    "        x = fun.max_pool2d(x, kernel_size=2)\n",
    "\n",
    "        x = x.reshape(x.size(0), -1)\n",
    "\n",
    "        x = fun.leaky_relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ],
   "id": "6106294ca60c4799",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Model Training",
   "id": "83f8c73d348a535d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Training function",
   "id": "ffeeeb5c4063c3eb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-29T10:58:28.931738Z",
     "start_time": "2025-11-29T10:58:28.927165Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_model(model: nn.Module,\n",
    "                train_loader: AnimalImageGenerator,\n",
    "                val_loader: AnimalImageGenerator,\n",
    "                criterion: nn.Module,\n",
    "                optimizer: torch.optim.Optimizer,\n",
    "                device: torch.device,\n",
    "                epochs: int = 10,\n",
    "                scheduler=None):\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    for epoch in tqdm(range(1, epochs+1), desc=\"Training model\"):\n",
    "    # for epoch in range(1, epochs+1):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        # for images, labels in train_loader:\n",
    "        for images, labels in train_loader:\n",
    "            images = images.float().to(device)\n",
    "            labels = labels.long().to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "        train_loss = running_loss / total\n",
    "        train_acc = correct / total\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images = images.float().to(device)\n",
    "                labels = labels.long().to(device)\n",
    "\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                val_loss += loss.item() * images.size(0)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                val_correct += (preds == labels).sum().item()\n",
    "                val_total += labels.size(0)\n",
    "\n",
    "        val_loss /= val_total\n",
    "        val_acc = val_correct / val_total\n",
    "\n",
    "        if scheduler:\n",
    "            scheduler.step(val_loss)\n",
    "\n",
    "        print(f\"Epoch {epoch}/{epochs} | \"\n",
    "              f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f} | \"\n",
    "              f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "        ## TODO: add f1 score"
   ],
   "id": "e17813431b74b029",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Training",
   "id": "4d4668dc88418f3c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Set-up",
   "id": "d4d05874f7518aae"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-29T10:58:28.985469Z",
     "start_time": "2025-11-29T10:58:28.935624Z"
    }
   },
   "cell_type": "code",
   "source": [
    "img_class_model = ImageClassifier(NUM_CLASSES)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(img_class_model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"device: {device}\")\n"
   ],
   "id": "d4f85be2913fa843",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-29T11:20:30.269559Z",
     "start_time": "2025-11-29T10:58:28.989293Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# TRAINING\n",
    "train_model(model=img_class_model,\n",
    "            train_loader=train_loader,\n",
    "            val_loader=val_loader,\n",
    "            criterion=criterion,\n",
    "            optimizer=optimizer,\n",
    "            device=device,\n",
    "            epochs=50,\n",
    "            scheduler=None)"
   ],
   "id": "e5df0fcd7b09431b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:   2%|▏         | 1/50 [01:11<58:43, 71.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 | Train Loss: 1.9547, Train Acc: 0.3053 | Val Loss: 1.6509, Val Acc: 0.4041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:   4%|▍         | 2/50 [01:35<34:40, 43.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50 | Train Loss: 1.7794, Train Acc: 0.3697 | Val Loss: 1.6030, Val Acc: 0.4355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:   6%|▌         | 3/50 [01:58<26:49, 34.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/50 | Train Loss: 1.7072, Train Acc: 0.3959 | Val Loss: 1.5181, Val Acc: 0.4430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:   8%|▊         | 4/50 [02:22<22:58, 29.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/50 | Train Loss: 1.6601, Train Acc: 0.4165 | Val Loss: 1.6030, Val Acc: 0.4149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  10%|█         | 5/50 [02:45<20:43, 27.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/50 | Train Loss: 1.6066, Train Acc: 0.4328 | Val Loss: 1.5260, Val Acc: 0.4711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  12%|█▏        | 6/50 [03:09<19:13, 26.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/50 | Train Loss: 1.5791, Train Acc: 0.4436 | Val Loss: 1.4121, Val Acc: 0.4901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  14%|█▍        | 7/50 [03:32<18:08, 25.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/50 | Train Loss: 1.5492, Train Acc: 0.4571 | Val Loss: 1.4020, Val Acc: 0.4959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  16%|█▌        | 8/50 [03:55<17:18, 24.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/50 | Train Loss: 1.5118, Train Acc: 0.4698 | Val Loss: 1.4242, Val Acc: 0.4868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  18%|█▊        | 9/50 [04:19<16:37, 24.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/50 | Train Loss: 1.5030, Train Acc: 0.4737 | Val Loss: 1.4983, Val Acc: 0.4843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  20%|██        | 10/50 [04:42<16:02, 24.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50 | Train Loss: 1.4788, Train Acc: 0.4810 | Val Loss: 1.3499, Val Acc: 0.5207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  22%|██▏       | 11/50 [05:06<15:34, 23.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/50 | Train Loss: 1.4647, Train Acc: 0.4832 | Val Loss: 1.3592, Val Acc: 0.5198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  24%|██▍       | 12/50 [05:30<15:08, 23.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/50 | Train Loss: 1.4320, Train Acc: 0.4991 | Val Loss: 1.3036, Val Acc: 0.5388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  26%|██▌       | 13/50 [05:54<14:43, 23.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/50 | Train Loss: 1.4206, Train Acc: 0.5008 | Val Loss: 1.3549, Val Acc: 0.5157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  28%|██▊       | 14/50 [06:18<14:18, 23.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/50 | Train Loss: 1.4085, Train Acc: 0.5052 | Val Loss: 1.2835, Val Acc: 0.5488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  30%|███       | 15/50 [06:41<13:53, 23.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/50 | Train Loss: 1.3848, Train Acc: 0.5180 | Val Loss: 1.2863, Val Acc: 0.5496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  32%|███▏      | 16/50 [07:05<13:30, 23.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/50 | Train Loss: 1.3782, Train Acc: 0.5178 | Val Loss: 1.2991, Val Acc: 0.5438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  34%|███▍      | 17/50 [07:29<13:06, 23.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/50 | Train Loss: 1.3710, Train Acc: 0.5195 | Val Loss: 1.2772, Val Acc: 0.5496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  36%|███▌      | 18/50 [07:53<12:42, 23.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/50 | Train Loss: 1.3537, Train Acc: 0.5297 | Val Loss: 1.2086, Val Acc: 0.5645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  38%|███▊      | 19/50 [08:17<12:18, 23.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/50 | Train Loss: 1.3340, Train Acc: 0.5341 | Val Loss: 1.2426, Val Acc: 0.5661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  40%|████      | 20/50 [08:40<11:54, 23.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/50 | Train Loss: 1.3200, Train Acc: 0.5426 | Val Loss: 1.2272, Val Acc: 0.5645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  42%|████▏     | 21/50 [09:04<11:30, 23.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/50 | Train Loss: 1.3209, Train Acc: 0.5372 | Val Loss: 1.1796, Val Acc: 0.5736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  44%|████▍     | 22/50 [09:28<11:06, 23.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/50 | Train Loss: 1.3257, Train Acc: 0.5380 | Val Loss: 1.1949, Val Acc: 0.5810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  46%|████▌     | 23/50 [09:52<10:43, 23.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/50 | Train Loss: 1.3155, Train Acc: 0.5414 | Val Loss: 1.2141, Val Acc: 0.5752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  48%|████▊     | 24/50 [10:16<10:19, 23.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/50 | Train Loss: 1.3114, Train Acc: 0.5457 | Val Loss: 1.1590, Val Acc: 0.5810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  50%|█████     | 25/50 [10:40<09:56, 23.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/50 | Train Loss: 1.2845, Train Acc: 0.5563 | Val Loss: 1.1612, Val Acc: 0.5975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  52%|█████▏    | 26/50 [11:06<09:49, 24.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/50 | Train Loss: 1.2799, Train Acc: 0.5519 | Val Loss: 1.1641, Val Acc: 0.5744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  54%|█████▍    | 27/50 [11:33<09:46, 25.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/50 | Train Loss: 1.2872, Train Acc: 0.5509 | Val Loss: 1.1344, Val Acc: 0.6124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  56%|█████▌    | 28/50 [12:01<09:34, 26.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/50 | Train Loss: 1.2543, Train Acc: 0.5610 | Val Loss: 1.1201, Val Acc: 0.6025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  58%|█████▊    | 29/50 [12:28<09:16, 26.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/50 | Train Loss: 1.2568, Train Acc: 0.5624 | Val Loss: 1.1450, Val Acc: 0.5942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  60%|██████    | 30/50 [12:56<08:55, 26.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/50 | Train Loss: 1.2568, Train Acc: 0.5622 | Val Loss: 1.0285, Val Acc: 0.6388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  62%|██████▏   | 31/50 [13:23<08:32, 26.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/50 | Train Loss: 1.2295, Train Acc: 0.5715 | Val Loss: 1.0269, Val Acc: 0.6207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  64%|██████▍   | 32/50 [13:51<08:07, 27.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/50 | Train Loss: 1.2351, Train Acc: 0.5713 | Val Loss: 1.1317, Val Acc: 0.6050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  66%|██████▌   | 33/50 [14:18<07:41, 27.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/50 | Train Loss: 1.2296, Train Acc: 0.5729 | Val Loss: 1.1539, Val Acc: 0.5909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  68%|██████▊   | 34/50 [14:45<07:15, 27.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/50 | Train Loss: 1.2137, Train Acc: 0.5815 | Val Loss: 1.0480, Val Acc: 0.6289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  70%|███████   | 35/50 [15:12<06:47, 27.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/50 | Train Loss: 1.2414, Train Acc: 0.5725 | Val Loss: 1.1352, Val Acc: 0.6165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  72%|███████▏  | 36/50 [15:40<06:21, 27.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/50 | Train Loss: 1.2143, Train Acc: 0.5777 | Val Loss: 1.0695, Val Acc: 0.6207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  74%|███████▍  | 37/50 [16:07<05:54, 27.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/50 | Train Loss: 1.2032, Train Acc: 0.5807 | Val Loss: 1.1034, Val Acc: 0.6025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  76%|███████▌  | 38/50 [16:34<05:27, 27.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/50 | Train Loss: 1.2072, Train Acc: 0.5803 | Val Loss: 1.0340, Val Acc: 0.6289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  78%|███████▊  | 39/50 [17:01<04:59, 27.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/50 | Train Loss: 1.1981, Train Acc: 0.5879 | Val Loss: 1.0546, Val Acc: 0.6207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  80%|████████  | 40/50 [17:29<04:32, 27.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/50 | Train Loss: 1.1936, Train Acc: 0.5865 | Val Loss: 1.0529, Val Acc: 0.6223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  82%|████████▏ | 41/50 [17:56<04:05, 27.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/50 | Train Loss: 1.1983, Train Acc: 0.5861 | Val Loss: 1.0641, Val Acc: 0.6107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  84%|████████▍ | 42/50 [18:23<03:37, 27.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/50 | Train Loss: 1.1785, Train Acc: 0.5936 | Val Loss: 1.1106, Val Acc: 0.6149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  86%|████████▌ | 43/50 [18:50<03:10, 27.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/50 | Train Loss: 1.1762, Train Acc: 0.5967 | Val Loss: 0.9739, Val Acc: 0.6512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  88%|████████▊ | 44/50 [19:17<02:43, 27.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/50 | Train Loss: 1.1535, Train Acc: 0.6032 | Val Loss: 1.0319, Val Acc: 0.6215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  90%|█████████ | 45/50 [19:45<02:15, 27.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/50 | Train Loss: 1.1601, Train Acc: 0.5965 | Val Loss: 1.0567, Val Acc: 0.6397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  92%|█████████▏| 46/50 [20:12<01:48, 27.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/50 | Train Loss: 1.1459, Train Acc: 0.6039 | Val Loss: 1.0654, Val Acc: 0.6347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  94%|█████████▍| 47/50 [20:39<01:21, 27.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/50 | Train Loss: 1.1497, Train Acc: 0.6005 | Val Loss: 1.0036, Val Acc: 0.6347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  96%|█████████▌| 48/50 [21:06<00:54, 27.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/50 | Train Loss: 1.1432, Train Acc: 0.6047 | Val Loss: 1.0679, Val Acc: 0.6281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  98%|█████████▊| 49/50 [21:34<00:27, 27.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/50 | Train Loss: 1.1470, Train Acc: 0.6060 | Val Loss: 0.9951, Val Acc: 0.6628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model: 100%|██████████| 50/50 [22:01<00:00, 26.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 | Train Loss: 1.1330, Train Acc: 0.6055 | Val Loss: 0.9942, Val Acc: 0.6579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Grad CAM Implementation\n",
    " -- On hold\n",
    " https://medium.com/@codetrade/grad-cam-in-pytorch-a-powerful-tool-for-visualize-explanations-from-deep-networks-bdc7caf0b282"
   ],
   "id": "b86d2775061e13df"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Single image predictions",
   "id": "5a88dc79ad1b72a7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-29T11:40:53.336201Z",
     "start_time": "2025-11-29T11:40:53.122087Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class SingleImageInput():\n",
    "    def __init__(self, target_size=(256, 256)):\n",
    "        self.target_size = target_size\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.Resize(target_size),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225]\n",
    "            ),\n",
    "        ])\n",
    "    def read_image(self, path) -> torch.Tensor:\n",
    "        print(path)\n",
    "        img = cv2.imread(path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = self.transform(img)\n",
    "        return img"
   ],
   "id": "ef644116c2c8e139",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m \u001B[38;5;28;43;01mclass\u001B[39;49;00m\u001B[38;5;250;43m \u001B[39;49m\u001B[34;43;01mSingleImageInput\u001B[39;49;00m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[32m      2\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mdef\u001B[39;49;00m\u001B[38;5;250;43m \u001B[39;49m\u001B[34;43m__init__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarget_size\u001B[49m\u001B[43m=\u001B[49m\u001B[43m(\u001B[49m\u001B[32;43m256\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[32;43m256\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[32m      3\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mtarget_size\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarget_size\u001B[49m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 13\u001B[39m, in \u001B[36mSingleImageInput\u001B[39m\u001B[34m()\u001B[39m\n\u001B[32m      3\u001B[39m     \u001B[38;5;28mself\u001B[39m.target_size = target_size\n\u001B[32m      4\u001B[39m     \u001B[38;5;28mself\u001B[39m.transform = transforms.Compose([\n\u001B[32m      5\u001B[39m         transforms.ToPILImage(),\n\u001B[32m      6\u001B[39m         transforms.Resize(target_size),\n\u001B[32m   (...)\u001B[39m\u001B[32m     11\u001B[39m         ),\n\u001B[32m     12\u001B[39m     ])\n\u001B[32m---> \u001B[39m\u001B[32m13\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mread_image\u001B[39m(\u001B[38;5;28mself\u001B[39m, path) -> \u001B[43mtorch\u001B[49m.Tensor:\n\u001B[32m     14\u001B[39m     \u001B[38;5;28mprint\u001B[39m(path)\n\u001B[32m     15\u001B[39m     img = cv2.imread(path)\n",
      "\u001B[31mNameError\u001B[39m: name 'torch' is not defined"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-29T11:41:37.050805Z",
     "start_time": "2025-11-29T11:41:37.015557Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ran_img_sample = pick_random(ANIMALS_DATAFRAME, ANIMALS_DATAFRAME.label == \"cane\")\n",
    "print(ran_img_sample)\n",
    "ImageReader = SingleImageInput(target_size=(256, 256))\n",
    "img = ImageReader.read_image(ran_img_sample).to(device)\n",
    "img.unsqueeze_(0)\n",
    "print(ran_img_sample)"
   ],
   "id": "75921675d9177435",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ANIMALS_DATAFRAME' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[5]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m ran_img_sample = pick_random(\u001B[43mANIMALS_DATAFRAME\u001B[49m, ANIMALS_DATAFRAME.label == \u001B[33m\"\u001B[39m\u001B[33mcane\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m      2\u001B[39m \u001B[38;5;28mprint\u001B[39m(ran_img_sample)\n\u001B[32m      3\u001B[39m ImageReader = SingleImageInput(target_size=(\u001B[32m256\u001B[39m, \u001B[32m256\u001B[39m))\n",
      "\u001B[31mNameError\u001B[39m: name 'ANIMALS_DATAFRAME' is not defined"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "img_class_model.eval()\n",
    "\n",
    "target_layer = img_class_model.conv3 ## last layer\n",
    "\n",
    "activations = []\n",
    "gradients = []\n",
    "\n",
    "def forward_hook(module, input, output):\n",
    "    activations.append(output)\n",
    "def backward_hook(module, grad_input, grad_output):\n",
    "    gradients.append(grad_output[0])\n",
    "\n",
    "f_handle = target_layer.register_forward_hook(forward_hook)\n",
    "b_handle = target_layer.register_full_backward_hook(backward_hook)\n",
    "\n",
    "\n",
    "img.requires_grad_(True)\n",
    "\n",
    "\n",
    "try:\n",
    "    img_class_model.zero_grad()\n",
    "    out = img_class_model(img)\n",
    "    predicted_l = out.argmax(dim=1).item()\n",
    "\n",
    "    score = out[0, predicted_l]\n",
    "    score.backward()\n",
    "finally:\n",
    "    f_handle.remove()\n",
    "    b_handle.remove()\n",
    "\n",
    "print(len(gradients))\n",
    "\n",
    "weights = torch.mean(gradients[0], dim=[2, 3])\n",
    "\n",
    "heatmap = torch.sum(weights * activations[0], dim=1).squeeze()\n",
    "heatmap = np.maximum(heatmap.cpu().detach().numpy(), 0)\n",
    "heatmap /= np.max(heatmap)  # normalization\n",
    "\n",
    "image = cv2.imread(ran_img_sample)\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "heatmap = cv2.resize(heatmap, (image.shape[1], image.shape[0]))\n",
    "heatmap = cv2.applyColorMap(np.uint8(255 * heatmap), cv2.COLORMAP_JET)\n",
    "superimposed_img = cv2.addWeighted(image, 0.6, heatmap, 0.4, 0)\n",
    "\n",
    "cv2.imshow('Grad-CAM', superimposed_img)\n",
    "cv2"
   ],
   "id": "155d7bb6e33607d9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "10569e112472a788"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
