{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Machine Learning - Image Classification",
   "id": "de369611418338b5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T21:45:23.604108Z",
     "start_time": "2025-11-28T21:45:23.600629Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#importing\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as fun\n",
    "\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch import optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "from utils import *"
   ],
   "id": "3d39034e8143cb63",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Database importing",
   "id": "36370301af86524b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T21:45:50.612156Z",
     "start_time": "2025-11-28T21:45:24.735787Z"
    }
   },
   "cell_type": "code",
   "source": [
    "load_dotenv()\n",
    "DAT_PATH = os.getenv(\"TRAIN_DATASET_PATH\")\n",
    "\n",
    "ANIMALS_DATAFRAME = load_dataset_info(\"../data/archive/raw-img\")"
   ],
   "id": "d9710a1ff3f0f4bf",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T21:45:50.630185Z",
     "start_time": "2025-11-28T21:45:50.619545Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_df, test_df = train_test_split(ANIMALS_DATAFRAME, test_size=0.01, random_state=37)\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.0526, random_state=37)"
   ],
   "id": "5cc1f9d00df31223",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T21:45:50.643753Z",
     "start_time": "2025-11-28T21:45:50.636749Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#setting up dataloaders\n",
    "\n",
    "TARGET_SIZE = (256, 256)\n",
    "MAX_SIZE = 500\n",
    "BATCH_SIZE = 128\n",
    "NUM_CLASSES = ANIMALS_DATAFRAME.label.nunique()\n",
    "CLASS_LABELS = {name: idx for idx, name in enumerate(np.sort(ANIMALS_DATAFRAME.label.unique()))}\n",
    "\n",
    "# vypocet frekvencie augmentacie -> aby nebol model biasnuty iba na majoritne categorie obrazkov\n",
    "counts = train_df.label.value_counts()\n",
    "max_count = counts.max()\n",
    "aug_strength = (max_count / counts).to_dict()\n",
    "\n",
    "print(aug_strength)\n",
    "#\n",
    "#   POMALE\n",
    "#\n",
    "# train_gen = AnimalImageGenerator(\n",
    "#     df=train_df,\n",
    "#     batch_size=BATCH_SIZE,\n",
    "#     target_size=TARGET_SIZE,\n",
    "#     num_classes=NUM_CLASSES,\n",
    "#     augment=True,\n",
    "#     shuffle=True,\n",
    "#     aug_strength=aug_strength,\n",
    "#     max_size=MAX_SIZE,\n",
    "#     class_mapping=CLASS_LABELS,\n",
    "# )\n",
    "#\n",
    "# test_gen = AnimalImageGenerator(\n",
    "#     df=test_df,\n",
    "#     batch_size=BATCH_SIZE,\n",
    "#     target_size=TARGET_SIZE,\n",
    "#     num_classes=NUM_CLASSES,\n",
    "#     augment=False,\n",
    "#     shuffle=False,\n",
    "#     max_size=MAX_SIZE,\n",
    "#     class_mapping=CLASS_LABELS,\n",
    "# )\n",
    "#\n",
    "# val_gen = AnimalImageGenerator(\n",
    "#     df=val_df,\n",
    "#     batch_size=BATCH_SIZE,\n",
    "#     target_size=TARGET_SIZE,\n",
    "#     num_classes=NUM_CLASSES,\n",
    "#     augment=False,\n",
    "#     shuffle=False,\n",
    "#     max_size=MAX_SIZE,\n",
    "#     class_mapping=CLASS_LABELS,\n",
    "# )\n"
   ],
   "id": "6a18fe6f83c8e0b6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cane': 1.0, 'ragno': 1.0084015034269291, 'gallina': 1.5689714482284143, 'cavallo': 1.8593558907460253, 'farfalla': 2.296576032225579, 'scoiattolo': 2.6003420752565565, 'mucca': 2.613753581661891, 'pecora': 2.6656925774400935, 'gatto': 2.9406834300451323, 'elefante': 3.3487518355359764}\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T21:45:50.655028Z",
     "start_time": "2025-11-28T21:45:50.648485Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.utils.data import WeightedRandomSampler\n",
    "\n",
    "\n",
    "#CHATOVINA ale ze vraj rychla\n",
    "\n",
    "def create_sampler(df, class_mapping):\n",
    "    labels = df[\"label\"].map(class_mapping).values\n",
    "    class_counts = np.bincount(labels)\n",
    "    class_weights = 1.0 / class_counts\n",
    "\n",
    "    sample_weights = class_weights[labels]\n",
    "    sampler = WeightedRandomSampler(\n",
    "        torch.from_numpy(sample_weights).float(),\n",
    "        num_samples=len(sample_weights),\n",
    "        replacement=True\n",
    "    )\n",
    "    return sampler\n",
    "\n",
    "train_dataset = AnimalDataset(\n",
    "    df=train_df,\n",
    "    class_mapping=CLASS_LABELS,\n",
    "    augment=True,\n",
    "    target_size=TARGET_SIZE,\n",
    ")\n",
    "\n",
    "val_dataset = AnimalDataset(\n",
    "    df=val_df,\n",
    "    class_mapping=CLASS_LABELS,\n",
    "    augment=False,\n",
    "    target_size=TARGET_SIZE,\n",
    ")\n",
    "\n",
    "sampler = create_sampler(train_df, CLASS_LABELS)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=64,\n",
    "    sampler=sampler,\n",
    "    num_workers=8,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=True\n",
    ")\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=64,\n",
    "    shuffle=False,\n",
    "    num_workers=8,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=True\n",
    ")\n"
   ],
   "id": "22dcbd10e815ce22",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Model implemetation",
   "id": "fbbb57b435bc15a3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T21:45:50.670179Z",
     "start_time": "2025-11-28T21:45:50.665243Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#PRE TUTO FUNKCIU NEGENERUJ ZIADNE KOMENTARE\n",
    "class ImageClassifier(nn.Module):\n",
    "    def __init__(self, classes: int):\n",
    "        super(ImageClassifier, self).__init__()\n",
    "        self.numberOfClasses = classes\n",
    "\n",
    "        # Convolution layres ONLY WORKS with RGB because of in_channels, kernel_size for filtering is 3 stride 1 padding 1 for size preservation\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1,padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "\n",
    "        # Significant for grad-CAM\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1,padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "\n",
    "        #\n",
    "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1,padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "\n",
    "        self.conv4 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1,padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(128)\n",
    "\n",
    "        self.conv5 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1,padding=1)\n",
    "        self.bn5 = nn.BatchNorm2d(256)\n",
    "        # Adaptive pooling to make model input-size agnostic / dont want to use it for now\n",
    "        # self.adaptive_pool = nn.AdaptiveAvgPool2d((4, 4))\n",
    "\n",
    "        #size is determined by conv channels and the reduction in size by conv channels\n",
    "        #channels * width * height because 256 /2 /2 /2 /2 /2 is 8\n",
    "        self.fc1 = nn.Linear(in_features=256*8*8, out_features=128)\n",
    "        self.fc2 = nn.Linear(in_features=128, out_features=self.numberOfClasses)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #Block 1\n",
    "        x = fun.relu(self.bn1(self.conv1(x)))\n",
    "        x = fun.max_pool2d(x, kernel_size=2) # zmensovanie velkosti\n",
    "\n",
    "        x = fun.relu(self.bn2(self.conv2(x)))\n",
    "        x = fun.max_pool2d(x, kernel_size=2)\n",
    "\n",
    "        x = fun.relu(self.bn3(self.conv3(x)))\n",
    "        x = fun.max_pool2d(x, kernel_size=2)\n",
    "\n",
    "        x = fun.relu(self.bn4(self.conv4(x)))\n",
    "        x = fun.max_pool2d(x, kernel_size=2)\n",
    "\n",
    "        x = fun.relu(self.bn5(self.conv5(x)))\n",
    "        x = fun.max_pool2d(x, kernel_size=2)\n",
    "\n",
    "        x = x.reshape(x.size(0), -1)\n",
    "\n",
    "        x = fun.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ],
   "id": "4917211e7761bf70",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Grad CAM Implementation\n",
    " -- On hold\n",
    " https://medium.com/@codetrade/grad-cam-in-pytorch-a-powerful-tool-for-visualize-explanations-from-deep-networks-bdc7caf0b282\n",
    "\n"
   ],
   "id": "78dd9163027c853"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Model Training",
   "id": "8a49ee32f84410ae"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Training function",
   "id": "b9e0ce08452c2799"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T21:45:50.680256Z",
     "start_time": "2025-11-28T21:45:50.675520Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_model(model: nn.Module,\n",
    "                train_loader: AnimalImageGenerator,\n",
    "                val_loader: AnimalImageGenerator,\n",
    "                criterion: nn.Module,\n",
    "                optimizer: torch.optim.Optimizer,\n",
    "                device: torch.device,\n",
    "                epochs: int = 10,\n",
    "                scheduler=None):\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    for epoch in range(1, epochs+1):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in tqdm(train_loader, desc=\"Training\"):\n",
    "            #orgiinal dataloader OBSOLETE\n",
    "            # images = torch.from_numpy(images).permute(0,3,1,2).float().to(device) # permute because the convolution layer gets input in the wrong order\n",
    "            # labels = torch.tensor(labels, dtype=torch.long, device=device)\n",
    "            #\n",
    "            images = images.float().to(device)\n",
    "            labels = labels.long().to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "        train_loss = running_loss / total\n",
    "        train_acc = correct / total\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in tqdm(val_loader, desc=\"Validation\"):\n",
    "                images = images.float().to(device)\n",
    "                labels = labels.long().to(device)\n",
    "\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                val_loss += loss.item() * images.size(0)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                val_correct += (preds == labels).sum().item()\n",
    "                val_total += labels.size(0)\n",
    "\n",
    "        val_loss /= val_total\n",
    "        val_acc = val_correct / val_total\n",
    "\n",
    "        if scheduler:\n",
    "            scheduler.step(val_loss)\n",
    "\n",
    "        print(f\"Epoch {epoch}/{epochs} | \"\n",
    "              f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f} | \"\n",
    "              f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "        ## TODO: add f1 score"
   ],
   "id": "ccfadbd579e53f46",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Training",
   "id": "5bf862f9c3a11a52"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-11-28T21:48:57.690454Z"
    }
   },
   "cell_type": "code",
   "source": [
    "img_class_model = ImageClassifier(NUM_CLASSES)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(img_class_model.parameters(), lr=0.001, momentum=0.9)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"device: {device}\")\n",
    "\n",
    "train_model(model=img_class_model,\n",
    "            train_loader=train_loader,\n",
    "            val_loader=val_loader,\n",
    "            criterion=criterion,\n",
    "            optimizer=optimizer,\n",
    "            device=device,\n",
    "            epochs=3,\n",
    "            scheduler=None)\n"
   ],
   "id": "6bba75ad8d81bff2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  48%|████▊     | 185/384 [00:14<00:15, 13.21it/s]"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Hyper parameter sweeping",
   "id": "6896e65a374b6d44"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "9d7c4537a330f912"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
