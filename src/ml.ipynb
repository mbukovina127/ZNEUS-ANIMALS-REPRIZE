{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Machine Learning - Image Classification",
   "id": "de369611418338b5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T16:14:48.017319Z",
     "start_time": "2025-11-28T16:14:42.021322Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#importing\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as fun\n",
    "\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch import optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "from utils import *"
   ],
   "id": "3d39034e8143cb63",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Database importing",
   "id": "36370301af86524b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T16:15:15.143556Z",
     "start_time": "2025-11-28T16:14:48.022961Z"
    }
   },
   "cell_type": "code",
   "source": [
    "load_dotenv()\n",
    "DAT_PATH = os.getenv(\"TRAIN_DATASET_PATH\")\n",
    "\n",
    "ANIMALS_DATAFRAME = load_dataset_info(\"../data/archive/raw-img\")"
   ],
   "id": "d9710a1ff3f0f4bf",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T16:15:15.209473Z",
     "start_time": "2025-11-28T16:15:15.200269Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_df, test_df = train_test_split(ANIMALS_DATAFRAME.sample(frac=0.5, random_state=37), test_size=0.01, random_state=37)\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.0526, random_state=37)"
   ],
   "id": "5cc1f9d00df31223",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T16:16:34.498941Z",
     "start_time": "2025-11-28T16:16:34.491175Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#setting up dataloaders\n",
    "\n",
    "TARGET_SIZE = (256, 256)\n",
    "MAX_SIZE = 500\n",
    "BATCH_SIZE = 128\n",
    "NUM_CLASSES = ANIMALS_DATAFRAME.label.nunique()\n",
    "CLASS_LABELS = {name: idx for idx, name in enumerate(np.sort(ANIMALS_DATAFRAME.label.unique()))}\n",
    "\n",
    "# vypocet frekvencie augmentacie -> aby nebol model biasnuty iba na majoritne categorie obrazkov\n",
    "counts = train_df.label.value_counts()\n",
    "max_count = counts.max()\n",
    "aug_strength = (max_count / counts).to_dict()\n",
    "\n",
    "print(aug_strength)\n",
    "#\n",
    "#   POMALE\n",
    "#\n",
    "# train_gen = AnimalImageGenerator(\n",
    "#     df=train_df,\n",
    "#     batch_size=BATCH_SIZE,\n",
    "#     target_size=TARGET_SIZE,\n",
    "#     num_classes=NUM_CLASSES,\n",
    "#     augment=True,\n",
    "#     shuffle=True,\n",
    "#     aug_strength=aug_strength,\n",
    "#     max_size=MAX_SIZE,\n",
    "#     class_mapping=CLASS_LABELS,\n",
    "# )\n",
    "#\n",
    "# test_gen = AnimalImageGenerator(\n",
    "#     df=test_df,\n",
    "#     batch_size=BATCH_SIZE,\n",
    "#     target_size=TARGET_SIZE,\n",
    "#     num_classes=NUM_CLASSES,\n",
    "#     augment=False,\n",
    "#     shuffle=False,\n",
    "#     max_size=MAX_SIZE,\n",
    "#     class_mapping=CLASS_LABELS,\n",
    "# )\n",
    "#\n",
    "# val_gen = AnimalImageGenerator(\n",
    "#     df=val_df,\n",
    "#     batch_size=BATCH_SIZE,\n",
    "#     target_size=TARGET_SIZE,\n",
    "#     num_classes=NUM_CLASSES,\n",
    "#     augment=False,\n",
    "#     shuffle=False,\n",
    "#     max_size=MAX_SIZE,\n",
    "#     class_mapping=CLASS_LABELS,\n",
    "# )\n"
   ],
   "id": "6a18fe6f83c8e0b6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cane': 1.0, 'ragno': 1.0594104308390022, 'gallina': 1.5934515688949522, 'cavallo': 1.9194741166803615, 'farfalla': 2.3524672708962737, 'mucca': 2.636568848758465, 'scoiattolo': 2.6485260770975056, 'pecora': 2.7257876312718787, 'gatto': 3.0817941952506596, 'elefante': 3.4505169867060563}\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T16:15:15.240687Z",
     "start_time": "2025-11-28T16:15:15.232859Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.utils.data import WeightedRandomSampler\n",
    "\n",
    "\n",
    "#CHATOVINA ale ze vraj rychla\n",
    "\n",
    "def create_sampler(df, class_mapping):\n",
    "    labels = df[\"label\"].map(class_mapping).values\n",
    "    class_counts = np.bincount(labels)\n",
    "    class_weights = 1.0 / class_counts\n",
    "\n",
    "    sample_weights = class_weights[labels]\n",
    "    sampler = WeightedRandomSampler(\n",
    "        torch.from_numpy(sample_weights).float(),\n",
    "        num_samples=len(sample_weights),\n",
    "        replacement=True\n",
    "    )\n",
    "    return sampler\n",
    "\n",
    "train_dataset = AnimalDataset(\n",
    "    df=train_df,\n",
    "    class_mapping=CLASS_LABELS,\n",
    "    augment=True,\n",
    "    target_size=(224, 224)\n",
    ")\n",
    "\n",
    "val_dataset = AnimalDataset(\n",
    "    df=val_df,\n",
    "    class_mapping=CLASS_LABELS,\n",
    "    augment=False,\n",
    "    target_size=(224, 224)\n",
    ")\n",
    "\n",
    "sampler = create_sampler(train_df, CLASS_LABELS)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=64,\n",
    "    sampler=sampler,\n",
    "    num_workers=8,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=True\n",
    ")\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=64,\n",
    "    shuffle=False,\n",
    "    num_workers=8,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=True\n",
    ")\n"
   ],
   "id": "22dcbd10e815ce22",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T16:15:15.245819Z",
     "start_time": "2025-11-28T16:15:15.244378Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "4945c56cb8443cdb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T16:15:16.165353Z",
     "start_time": "2025-11-28T16:15:15.249868Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#testovaci vypis\n",
    "\n",
    "images, labels = train_gen[0]     # zavolá __getitem__(0) pre prvy batch\n",
    "print(\"Images shape:\", images.shape)\n",
    "print(\"Labels shape:\", labels.shape)\n",
    "print(\"Image dtype:\", images.dtype)\n",
    "print(\"Label sample:\", labels[0])"
   ],
   "id": "d2b55cb221211796",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images shape: (202, 256, 256, 3)\n",
      "Labels shape: (202,)\n",
      "Image dtype: uint8\n",
      "Label sample: 7\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Model implemetation",
   "id": "fbbb57b435bc15a3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T16:15:16.186522Z",
     "start_time": "2025-11-28T16:15:16.181755Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#PRE TUTO FUNKCIU NEGENERUJ ZIADNE KOMENTARE\n",
    "class ImageClassifier(nn.Module):\n",
    "    def __init__(self, classes: int):\n",
    "        super(ImageClassifier, self).__init__()\n",
    "        self.numberOfClasses = classes\n",
    "\n",
    "        # Convolution layres ONLY WORKS with RGB because of in_channels, kernel_size for filtering is 3 stride 1 padding 1 for size preservation\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1,padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "\n",
    "        # Significant for grad-CAM\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1,padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "\n",
    "        #\n",
    "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1,padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "\n",
    "        self.conv4 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1,padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(128)\n",
    "\n",
    "        self.conv5 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1,padding=1)\n",
    "        self.bn5 = nn.BatchNorm2d(256)\n",
    "        # Adaptive pooling to make model input-size agnostic / dont want to use it for now\n",
    "        # self.adaptive_pool = nn.AdaptiveAvgPool2d((4, 4))\n",
    "\n",
    "        #size is determined by conv channels and the reduction in size by conv channels\n",
    "        #channels * width * height because 256 /2 /2 /2 /2 /2 is 8\n",
    "        self.fc1 = nn.Linear(in_features=256*8*8, out_features=128)\n",
    "        self.fc2 = nn.Linear(in_features=128, out_features=self.numberOfClasses)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #Block 1\n",
    "        x = fun.relu(self.bn1(self.conv1(x)))\n",
    "        x = fun.max_pool2d(x, kernel_size=2) # zmensovanie velkosti\n",
    "\n",
    "        x = fun.relu(self.bn2(self.conv2(x)))\n",
    "        x = fun.max_pool2d(x, kernel_size=2)\n",
    "\n",
    "        x = fun.relu(self.bn3(self.conv3(x)))\n",
    "        x = fun.max_pool2d(x, kernel_size=2)\n",
    "\n",
    "        x = fun.relu(self.bn4(self.conv4(x)))\n",
    "        x = fun.max_pool2d(x, kernel_size=2)\n",
    "\n",
    "        x = fun.relu(self.bn5(self.conv5(x)))\n",
    "        x = fun.max_pool2d(x, kernel_size=2)\n",
    "\n",
    "        x = x.reshape(x.size(0), -1)\n",
    "\n",
    "        x = fun.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ],
   "id": "4917211e7761bf70",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Grad CAM Implementation\n",
    " -- On hold\n",
    " https://medium.com/@codetrade/grad-cam-in-pytorch-a-powerful-tool-for-visualize-explanations-from-deep-networks-bdc7caf0b282\n",
    "\n"
   ],
   "id": "78dd9163027c853"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Model Training",
   "id": "8a49ee32f84410ae"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Training function",
   "id": "b9e0ce08452c2799"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T16:15:16.198282Z",
     "start_time": "2025-11-28T16:15:16.190392Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_model(model: nn.Module,\n",
    "                train_loader: AnimalImageGenerator,\n",
    "                val_loader: AnimalImageGenerator,\n",
    "                criterion: nn.Module,\n",
    "                optimizer: torch.optim.Optimizer,\n",
    "                device: torch.device,\n",
    "                epochs: int = 10,\n",
    "                scheduler=None):\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    for epoch in range(1, epochs+1):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in tqdm(train_loader, desc=\"Training\"):\n",
    "            images = torch.from_numpy(images).permute(0,3,1,2).float().to(device) # permute because the convolution layer gets input in the wrong order\n",
    "            # images = torch.tensor(images, dtype=torch.float32, device=device)\n",
    "            labels = torch.tensor(labels, dtype=torch.long, device=device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "        train_loss = running_loss / total\n",
    "        train_acc = correct / total\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images = torch.tensor(images, dtype=torch.float32, device=device)\n",
    "                labels = torch.tensor(labels, dtype=torch.long, device=device)\n",
    "\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                val_loss += loss.item() * images.size(0)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                val_correct += (preds == labels).sum().item()\n",
    "                val_total += labels.size(0)\n",
    "\n",
    "        val_loss /= val_total\n",
    "        val_acc = val_correct / val_total\n",
    "\n",
    "        if scheduler:\n",
    "            scheduler.step(val_loss)\n",
    "\n",
    "        print(f\"Epoch {epoch}/{epochs} | \"\n",
    "              f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f} | \"\n",
    "              f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "        ## TODO: add f1 score"
   ],
   "id": "ccfadbd579e53f46",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Training",
   "id": "5bf862f9c3a11a52"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T16:16:12.011411Z",
     "start_time": "2025-11-28T16:15:16.203258Z"
    }
   },
   "cell_type": "code",
   "source": [
    "img_class_model = ImageClassifier(NUM_CLASSES)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(img_class_model.parameters(), lr=0.001, momentum=0.9)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"device: {device}\")\n",
    "\n",
    "train_model(model=img_class_model,\n",
    "            train_loader=train_gen,\n",
    "            val_loader=val_gen,\n",
    "            criterion=criterion,\n",
    "            optimizer=optimizer,\n",
    "            device=device,\n",
    "            epochs=1,\n",
    "            scheduler=None)\n"
   ],
   "id": "6bba75ad8d81bff2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 9/95 [00:55<08:51,  6.18s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[9]\u001B[39m\u001B[32m, line 7\u001B[39m\n\u001B[32m      4\u001B[39m device = torch.device(\u001B[33m\"\u001B[39m\u001B[33mcuda\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m torch.cuda.is_available() \u001B[38;5;28;01melse\u001B[39;00m \u001B[33m\"\u001B[39m\u001B[33mcpu\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m      5\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mdevice: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdevice\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m)\n\u001B[32m----> \u001B[39m\u001B[32m7\u001B[39m \u001B[43mtrain_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m=\u001B[49m\u001B[43mimg_class_model\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m      8\u001B[39m \u001B[43m            \u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtrain_gen\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m      9\u001B[39m \u001B[43m            \u001B[49m\u001B[43mval_loader\u001B[49m\u001B[43m=\u001B[49m\u001B[43mval_gen\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     10\u001B[39m \u001B[43m            \u001B[49m\u001B[43mcriterion\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcriterion\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     11\u001B[39m \u001B[43m            \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m=\u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     12\u001B[39m \u001B[43m            \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     13\u001B[39m \u001B[43m            \u001B[49m\u001B[43mepochs\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m1\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m     14\u001B[39m \u001B[43m            \u001B[49m\u001B[43mscheduler\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[8]\u001B[39m\u001B[32m, line 28\u001B[39m, in \u001B[36mtrain_model\u001B[39m\u001B[34m(model, train_loader, val_loader, criterion, optimizer, device, epochs, scheduler)\u001B[39m\n\u001B[32m     25\u001B[39m loss.backward()\n\u001B[32m     26\u001B[39m optimizer.step()\n\u001B[32m---> \u001B[39m\u001B[32m28\u001B[39m running_loss += \u001B[43mloss\u001B[49m\u001B[43m.\u001B[49m\u001B[43mitem\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m * images.size(\u001B[32m0\u001B[39m)\n\u001B[32m     29\u001B[39m _, preds = torch.max(outputs, \u001B[32m1\u001B[39m)\n\u001B[32m     30\u001B[39m correct += (preds == labels).sum().item()\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Hyper parameter sweeping",
   "id": "6896e65a374b6d44"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "9d7c4537a330f912"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
